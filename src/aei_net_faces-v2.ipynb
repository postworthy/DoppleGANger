{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b076bd1a-b236-4fbc-953d-8295b25122ae",
   "metadata": {},
   "source": [
    "# ðŸ¤ª AEI_NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fda92c-d4f3-459b-a60d-e7e75f68dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE YOU START YOU NEED TO HAVE EXECUTED pretraining.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "327dc159-f195-45fd-9ab9-bc2dd26208a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 15:24:17.385364: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-11 15:24:17.446034: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-11 15:24:17.464009: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-11 15:24:18.232722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-11 15:24:18.234367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-11 15:24:18.234446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set memory growth to avoid pre-allocation of all GPU memory\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84acc7be-6764-4668-b2bb-178f63deeed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Memory limit set to 13510.2 MB per GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 15:24:29.104318: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-11 15:24:29.105387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-11 15:24:29.105475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-11 15:24:29.105517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-11 15:24:29.418729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-11 15:24:29.418836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-11 15:24:29.418884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-02-11 15:24:29.418937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13510 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Limit TensorFlow to 80% of GPU memory\n",
    "from gpu_memory import limit_gpu_memory \n",
    "#limit_gpu_memory(0.35)\n",
    "limit_gpu_memory(0.55)\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5a13af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4090, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 15:24:43.579609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16') #This was produucing NAN when training beyond ~7 epochs\n",
    "tf.config.optimizer.set_jit(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e6268-ebd7-4feb-86db-1fe7abccdbe5",
   "metadata": {},
   "source": [
    "## 0. Parameters <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b2ee6ce-129f-4833-b0c5-fa567381c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 32\n",
    "NUM_FEATURES = 512\n",
    "Z_DIM = 200\n",
    "LEARNING_RATE = 1e-4 #0.0005\n",
    "WEIGHT_DECAY = 1e-7\n",
    "EPOCHS = 5\n",
    "BETA = 2000\n",
    "LOAD_MODEL = True\n",
    "TAKE_BATCHES = 500\n",
    "VALIDATION_SET_SIZE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7716fac-0010-49b0-b98e-53be2259edde",
   "metadata": {},
   "source": [
    "## 1. Prepare the data <a name=\"prepare\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e6a2ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 15:26:11.075258: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "from data_loader import get_training_data\n",
    "\n",
    "train, validation = get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03f32fd-addb-4c9b-906c-a5f1934df7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "((img_batch, embed_batch), (Y_target, Y_target_x2)) = next(iter(train))\n",
    "train_sample = img_batch.numpy()\n",
    "result_sample = Y_target.numpy()\n",
    "result_x2_sample = Y_target_x2.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40434cdf-9134-4ed0-be76-d1d5cda3ca97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa53709f-7f3f-483b-9db8-2e5f9b9942c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some faces from the training set\n",
    "from notebooks.utils import display\n",
    "\n",
    "display(train_sample, 8, cmap=None)\n",
    "display(result_sample, 8, cmap=None)\n",
    "display(result_x2_sample, 8, cmap=None)\n",
    "print(result_sample[0])\n",
    "print(embed_batch.shape)\n",
    "print(embed_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff50401-3abe-4c10-bba8-b35bc13ad7d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Build the AEI_NET <a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad9761-9756-45b3-83ef-ee3d9218d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aei_net import get_model\n",
    "generator = get_model(num_blocks=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2675fd-2116-4924-85a7-f1bd67b40233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from discriminator import MinimalPatchGAN\n",
    "discriminator = MinimalPatchGAN(ndf=64, num_layers=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b14665-4359-447b-be58-3fd58ba69084",
   "metadata": {},
   "source": [
    "## 3. Train the AEI_NET <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429fdad-ea9c-45a2-a556-eb950d793824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow_addons.optimizers import AdamW\n",
    "#optimizer = AdamW(\n",
    "#    weight_decay=WEIGHT_DECAY,\n",
    "#    learning_rate=LEARNING_RATE)\n",
    "##model.compile(optimizer=optimizer, loss=['mse', None])  \n",
    "#model.compile(optimizer=optimizer, loss=['mae', None])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c525e44b-b3bb-489c-9d35-fcfe3e714e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_callbacks import get_callbacks\n",
    "model_checkpoint_callback, tensorboard_callback, image_generator = get_callbacks(train)\n",
    "terminate_on_nan = tf.keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "class FinalModelSaver(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_path):\n",
    "        super().__init__()\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        Save the model after each epoch.\n",
    "        \"\"\"\n",
    "        save_path_with_epoch = f\"{self.save_path}_epoch_{epoch + 1}\"\n",
    "        self.model.save(save_path_with_epoch)\n",
    "        print(f\"Model saved at: {save_path_with_epoch}\")\n",
    "        self.model.save(f\"{self.save_path}_latest\")\n",
    "        print(f\"Model saved at: {self.save_path}_latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064258bb-bddc-4b26-8719-436ef847809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AEIGANModel import AEIGANModel\n",
    "aei_gan_model = AEIGANModel(generator=generator, \n",
    "                            discriminator=discriminator,\n",
    "                            lambda_recon=150.0,\n",
    "                            lambda_adv=0.5,\n",
    "                            lambda_id=45.0\n",
    "                           )\n",
    "\n",
    "from tensorflow_addons.optimizers import AdamW\n",
    "aei_gan_model.compile(\n",
    "    g_optimizer=AdamW(learning_rate=4e-4, beta_1=0, beta_2=0.999, weight_decay=1e-4), \n",
    "    d_optimizer=AdamW(learning_rate=4e-6, beta_1=0, beta_2=0.999, weight_decay=1e-4), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad6471-1979-4d39-836b-1a56230b6eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "# Load old weights if required\n",
    "if LOAD_MODEL:\n",
    "    aei_gan_model.load_weights(\"./models/aei_net_gan_kitchensink_128_v3_150_0.5_45_15_latest\")\n",
    "    aei_gan_model.g_optimizer=AdamW(learning_rate=4e-4, beta_1=0, beta_2=0.999, weight_decay=1e-4) \n",
    "    aei_gan_model.d_optimizer=AdamW(learning_rate=4e-6, beta_1=0, beta_2=0.999, weight_decay=1e-4)\n",
    "    tmp = aei_gan_model.predict(train.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65b30c-2a1c-40c1-b929-e49129107f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_img = tf.zeros([1, 64, 64, 3], dtype=tf.float32)\n",
    "dummy_embed = tf.zeros([1, 512], dtype=tf.float32)\n",
    "aei_gan_model((dummy_img, dummy_embed), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301bd3bf-63ce-4b1f-84c6-458dcac98680",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = aei_gan_model.fit(\n",
    "    train,\n",
    "    validation_data=validation,  # optional\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[\n",
    "        FinalModelSaver(\"./models/aei_net_gan_kitchensink_128_v3_150_0.5_45_15\"),\n",
    "        terminate_on_nan,\n",
    "        model_checkpoint_callback,\n",
    "        # tensorboard_callback,\n",
    "        image_generator,\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e6ed0c-edea-4f55-be1d-bfc4c68ea227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_resolution import SuperResModel\n",
    "superres_model = SuperResModel(aei_gan_model.generator)\n",
    "superres_model.compile(\n",
    "    g_optimizer=AdamW(learning_rate=4e-4, beta_1=0, beta_2=0.999, weight_decay=1e-4), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc20410a-5711-4757-aa03-eeab032afdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.optimizers import AdamW\n",
    "\n",
    "# Load old weights if required\n",
    "if LOAD_MODEL:\n",
    "    superres_model.load_weights(\"./models/superres_aei_net_gan_kitchensink_128_v3_150_0.5_45_15_latest\")\n",
    "    superres_model.g_optimizer=AdamW(learning_rate=4e-4, beta_1=0, beta_2=0.999, weight_decay=1e-4) \n",
    "    tmp = superres_model.predict(train.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175629e4-d93d-4214-a448-6c5f8d6e2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_img = tf.zeros([1, 64, 64, 3], dtype=tf.float32)\n",
    "dummy_embed = tf.zeros([1, 512], dtype=tf.float32)\n",
    "superres_model((dummy_img, dummy_embed), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e79d5f-b5fa-4b5b-a2dd-6238c6526f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "superres_model.fit(\n",
    "    train, \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=[\n",
    "        FinalModelSaver(\"./models/superres_aei_net_gan_kitchensink_128_v3_150_0.5_45_15\"),\n",
    "        terminate_on_nan,\n",
    "        model_checkpoint_callback,\n",
    "        # tensorboard_callback,\n",
    "        image_generator,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd76ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682fb369-33fb-4f16-a601-47db56de3fd2",
   "metadata": {},
   "source": [
    "## 3. Reconstruct using the variational autoencoder <a name=\"reconstruct\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd27341-a02b-4740-83bf-f257741afbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for layer in generator.layers:\n",
    "    print(layer.name, layer.input_shape)\n",
    "    if layer.name == \"model_1\":\n",
    "        for l in layer.layers:\n",
    "            print(l.name, l.input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1fece5-77a8-4510-be7d-713cc08aee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of the test set\n",
    "((img_batch, embed_batch), (Y_target, Y_target_x2)) = next(iter(train.skip(10)))\n",
    "example_images = img_batch.numpy()\n",
    "example_embed = embed_batch.numpy()\n",
    "example_target = Y_target.numpy()\n",
    "example_target_x2 = Y_target_x2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7fba06-6a5f-49c2-82a7-e6265acf1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create autoencoder predictions and display\n",
    "Y_pred = aei_gan_model([example_images, example_embed])\n",
    "y_upsampled = superres_model([example_images, example_embed])\n",
    "\n",
    "predicted_images = np.clip(Y_pred * 255, 0, 255).astype(np.uint8)\n",
    "predicted_images_x2 = np.clip(y_upsampled * 255, 0, 255).astype(np.uint8)\n",
    "print(\"Example real faces\")\n",
    "display(example_images)\n",
    "print(\"Reconstructions\")\n",
    "display(predicted_images)\n",
    "print(\"Reconstructions x2\")\n",
    "display(predicted_images_x2)\n",
    "print(\"Target\")\n",
    "display(example_target)\n",
    "print(\"Target x2\")\n",
    "display(example_target_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f21e8c0-331f-4f73-a73c-8a0e4c1e45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import main as infer\n",
    "models = [\n",
    "    (3, \"aei_net_gan_weights_latest\", \"superres_weights_superres_latest\")\n",
    "]\n",
    "for num_blocks, m, s in models:\n",
    "    infer(\n",
    "        model_paths = (f\"./models/{m}\", f\"./models/{s}\"),\n",
    "        source_image_path = \"./samples/1.jpg\", \n",
    "        target_image_path = \"./samples/2.jpg\",\n",
    "        output_file_name=f\"{m}-o1.png\",\n",
    "        num_blocks=num_blocks\n",
    "    )\n",
    "    infer(\n",
    "        model_paths = (f\"./models/{m}\", f\"./models/{s}\"),\n",
    "        source_image_path = \"./samples/3.jpg\", \n",
    "        target_image_path = \"./samples/2.jpg\",\n",
    "        output_file_name=f\"{m}-o2.png\",\n",
    "        num_blocks=num_blocks\n",
    "    )\n",
    "    infer(\n",
    "        model_paths = (f\"./models/{m}\", f\"./models/{s}\"),\n",
    "        source_image_path = \"./samples/4.jpg\", \n",
    "        target_image_path = \"./samples/2.jpg\",\n",
    "        output_file_name=f\"{m}-o3.png\",\n",
    "        num_blocks=num_blocks\n",
    "    )\n",
    "    infer(\n",
    "        model_paths = (f\"./models/{m}\", f\"./models/{s}\"),\n",
    "        source_image_path = \"./samples/generated_img_004_6.png\", \n",
    "        target_image_path = \"./samples/2.jpg\",\n",
    "        output_file_name=f\"{m}-o4.png\",\n",
    "        num_blocks=num_blocks\n",
    "    )\n",
    "    infer(\n",
    "        model_paths = (f\"./models/{m}\", f\"./models/{s}\"),\n",
    "        source_image_path = \"./samples/generated_img_005_8.png\", \n",
    "        target_image_path = \"./samples/2.jpg\",\n",
    "        output_file_name=f\"{m}-o4.png\",\n",
    "        num_blocks=num_blocks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdce726-9650-417b-a50c-e7000d761c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c640f-2b75-4478-9096-e5ffdabdba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cached_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24406e96-5417-4da2-b8c7-e78ef2102f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_resolution import SuperResModel\n",
    "model = SuperResModel(aei_gan_model.generator)\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c16f403-537c-4a8e-9b21-1db5358b7b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b14e4-0886-4dcb-a60e-9a67f45e3f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
